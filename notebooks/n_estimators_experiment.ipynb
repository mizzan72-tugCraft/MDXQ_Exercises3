# スコア記録テンプレート（提出後に実行）
from score_analysis import record_score

print("\n📝 スコア記録用テンプレート")
print("提出後、以下のコードを実行してスコアを記録してください:\n")

for n_est in n_estimators_values:
    print(f"# n_estimators={n_est}のスコア記録")
    print(f"score_{n_est} = None  # 提出後にスコアを入力")
    print(f"if score_{n_est} is not None:")
    print(f"    record_score(")
    print(f"        current_score=score_{n_est},")
    print(f"        model_name='RandomForestRegressor (n_estimators={n_est})',")
    print(f"        features_used='店舗ID, 商品ID, 年, 月, 商品カテゴリID',")
    print(f"        notes='n_estimators最適化実験'")
    print(f"    )")
    print()

print("\n💡 ヒント: 最も良いスコアが出た設定で追加の特徴量エンジニアリングを実施しましょう！")## 🧠 n_estimators最適化の理論的考察

### n_estimatorsとRandomForestの関係

**1. バイアス-バリアンス トレードオフ:**
- **少ない木**: 高バイアス、低バリアンス（アンダーフィッティング）
- **多い木**: 低バイアス、高バリアンス（過学習の可能性）

**2. アンサンブル効果:**
- 複数の決定木の予測を平均化
- 個々の木の予測誤差を相殺
- 一般的に木の数が増えるほど安定

**3. 計算コストと性能:**
- 学習時間: O(n_estimators × データサイズ)
- 予測時間: O(n_estimators × 木の深さ)
- メモリ使用量: O(n_estimators × 木のサイズ)

### 現在の結果からの推測
- `n_estimators=100`がベスト → この問題に対する最適値付近
- `n_estimators=200`で悪化 → 過学習または計算の不安定性
- より小さい値での実験 → 計算効率と性能のバランス確認

### 期待される結果
- `n_estimators=50`: 100に近い性能、より高速
- `n_estimators=25`: やや性能低下、大幅な高速化
- 最適値は25-100の間に存在する可能性# 提出ファイル生成（各n_estimators値に対して）
now = datetime.datetime.now()
timestamp = now.strftime("%Y%m%d_%H%M%S")

submission_files = {}

for n_est in n_estimators_values:
    # 提出用データフレームを作成
    submission_copy = submission_df.copy()
    submission_copy[1] = results[n_est]['predictions']
    
    # ファイル名生成
    filename = f'../submissions/{timestamp}_Exercises3_Challenge_rf{n_est}.csv'
    submission_copy.to_csv(filename, index=False, header=False)
    
    submission_files[n_est] = filename
    print(f"✅ n_estimators={n_est}: {filename}")

print(f"\n🎯 提出ファイルが生成されました（{len(submission_files)}個）")
print("各ファイルをコンペティションサイトに提出してスコアを確認してください。")# n_estimators実験
n_estimators_values = [25, 50, 100, 200]
results = {}
predictions = {}

print("=" * 60)
print("🔬 n_estimators最適化実験")
print("=" * 60)

for n_est in n_estimators_values:
    print(f"\n🌳 n_estimators={n_est} で学習中...")
    
    # モデル定義と学習
    model = RandomForestRegressor(n_estimators=n_est, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    # 予測
    y_pred = model.predict(X_test)
    y_pred[y_pred < 0] = 0  # 負の値を0に変換
    
    # 結果を保存
    results[n_est] = {
        'model': model,
        'predictions': y_pred,
        'pred_min': y_pred.min(),
        'pred_max': y_pred.max(),
        'pred_mean': y_pred.mean()
    }
    
    print(f"   予測値の範囲: {y_pred.min():.2f} ～ {y_pred.max():.2f}")
    print(f"   予測値の平均: {y_pred.mean():.2f}")

print("\n✅ 全ての実験が完了しました")# データ前処理（ベストモデルと同じ処理）
sales_df['年'] = sales_df['日付'].apply(lambda x: x.split('-')[0])
sales_df['月'] = sales_df['日付'].apply(lambda x: x.split('-')[1])

# 月ごとの売上個数を集計
sales_month_df = sales_df.groupby(['商品ID', '店舗ID', '年', '月'])['売上個数'].sum().reset_index()

# 商品カテゴリIDを結合
train_df = pd.merge(sales_month_df, item_categories_df, on='商品ID', how='left')

# データ型を変換
train_df['年'] = train_df['年'].astype(int)
train_df['月'] = train_df['月'].astype(int)

# test_dfにも年と月を追加し、商品カテゴリIDを結合
test_df['年'] = 2022
test_df['月'] = 12
test_df = pd.merge(test_df, item_categories_df, on='商品ID', how='left')

# 特徴量とターゲット変数を定義
feature_columns = ['店舗ID', '商品ID', '年', '月', '商品カテゴリID']
target_column = '売上個数'

# 学習データとテストデータに分割
X_train = train_df[feature_columns]
y_train = train_df[target_column]
X_test = test_df[feature_columns]

print("データ前処理完了")
print(f"訓練データ形状: {X_train.shape}")
print(f"テストデータ形状: {X_test.shape}")# データ読み込み
base_dir = '../data/'
sales_df = pd.read_csv(base_dir + 'sales_history.csv')
item_categories_df = pd.read_csv(base_dir + 'item_categories.csv')
category_names_df = pd.read_csv(base_dir + 'category_names.csv')
test_df = pd.read_csv(base_dir + 'test.csv')
submission_df = pd.read_csv(base_dir + 'sample_submission.csv', header=None)# =============================================================================
# n_estimators最適化実験
# =============================================================================
# 
# 【実験目的】
# - n_estimators=100がベストスコア（3.07256739424164）
# - n_estimators=200で悪化（3.078811806610283）
# - より小さい値（50, 25）での性能を検証
# 
# 【n_estimatorsとは】
# - RandomForestで使用する決定木の個数
# - 多すぎる→過学習、計算コスト増
# - 少なすぎる→アンダーフィッティング、不安定
# - 最適値を見つけることが重要
# 
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import datetime
import os