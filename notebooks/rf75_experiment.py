# =============================================================================
# RandomForest n_estimators=75 å˜ä½“å®Ÿé¨“
# =============================================================================
# 
# ã€å®Ÿé¨“ç›®çš„ã€‘
# - n_estimators=75ãŒæœ€é©å€¤ã¨ã„ã†ä»®èª¬ã®æ¤œè¨¼
# - ç¾åœ¨ã®ãƒ™ã‚¹ãƒˆï¼ˆn_estimators=100, ã‚¹ã‚³ã‚¢3.07256739424164ï¼‰ã¨ã®æ¯”è¼ƒ
# - è¨ˆç®—åŠ¹ç‡ã¨äºˆæ¸¬ç²¾åº¦ã®ãƒãƒ©ãƒ³ã‚¹ç¢ºèª
# 
# ã€æœŸå¾…ã•ã‚Œã‚‹çµæœã€‘
# - ã‚¹ã‚³ã‚¢: 3.065-3.075 (ç¾åœ¨ã®ãƒ™ã‚¹ãƒˆã¨åŒç­‰ä»¥ä¸Š)
# - å­¦ç¿’æ™‚é–“: ç´„25%çŸ­ç¸®
# - äºˆæ¸¬å®‰å®šæ€§: ååˆ†ãªå“è³ªã‚’ç¶­æŒ
# 
# =============================================================================

import pandas as pd
import numpy as np
import datetime
import time
from sklearn.ensemble import RandomForestRegressor
import os

def main():
    print("=" * 70)
    print("ğŸ¯ RandomForest n_estimators=75 æœ€é©åŒ–å®Ÿé¨“")
    print("=" * 70)
    print("ä»®èª¬: n_estimators=75ãŒè¨ˆç®—åŠ¹ç‡ã¨äºˆæ¸¬ç²¾åº¦ã®æœ€é©ãƒãƒ©ãƒ³ã‚¹")
    print("=" * 70)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    base_dir = '../data/'
    
    try:
        sales_df = pd.read_csv(base_dir + 'sales_history.csv')
        item_categories_df = pd.read_csv(base_dir + 'item_categories.csv')
        category_names_df = pd.read_csv(base_dir + 'category_names.csv')
        test_df = pd.read_csv(base_dir + 'test.csv')
        submission_df = pd.read_csv(base_dir + 'sample_submission.csv', header=None)
        print("âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
    except FileNotFoundError as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        return
    
    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ï¼ˆãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¨åŒä¸€ã®å‡¦ç†ï¼‰
    print("\nğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
    
    # æ—¥ä»˜ã‹ã‚‰å¹´ã¨æœˆã‚’æŠ½å‡º
    sales_df['å¹´'] = sales_df['æ—¥ä»˜'].apply(lambda x: x.split('-')[0])
    sales_df['æœˆ'] = sales_df['æ—¥ä»˜'].apply(lambda x: x.split('-')[1])
    
    # æœˆã”ã¨ã®å£²ä¸Šå€‹æ•°ã‚’é›†è¨ˆ
    sales_month_df = sales_df.groupby(['å•†å“ID', 'åº—èˆ—ID', 'å¹´', 'æœˆ'])['å£²ä¸Šå€‹æ•°'].sum().reset_index()
    
    # å•†å“ã‚«ãƒ†ã‚´ãƒªIDã‚’çµåˆ
    train_df = pd.merge(sales_month_df, item_categories_df, on='å•†å“ID', how='left')
    
    # ãƒ‡ãƒ¼ã‚¿å‹ã‚’å¤‰æ›
    train_df['å¹´'] = train_df['å¹´'].astype(int)
    train_df['æœˆ'] = train_df['æœˆ'].astype(int)
    
    # test_dfã«ã‚‚å¹´ã¨æœˆã‚’è¿½åŠ ã—ã€å•†å“ã‚«ãƒ†ã‚´ãƒªIDã‚’çµåˆ
    test_df['å¹´'] = 2022
    test_df['æœˆ'] = 12
    test_df = pd.merge(test_df, item_categories_df, on='å•†å“ID', how='left')
    
    # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã‚’å®šç¾©
    feature_columns = ['åº—èˆ—ID', 'å•†å“ID', 'å¹´', 'æœˆ', 'å•†å“ã‚«ãƒ†ã‚´ãƒªID']
    target_column = 'å£²ä¸Šå€‹æ•°'
    
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    X_train = train_df[feature_columns]
    y_train = train_df[target_column]
    X_test = test_df[feature_columns]
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å®Œäº†")
    print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_train.shape}")
    print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {X_test.shape}")
    print(f"   ä½¿ç”¨ç‰¹å¾´é‡: {', '.join(feature_columns)}")
    
    # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ï¼ˆn_estimators=75ï¼‰
    print(f"\nğŸŒ³ RandomForestå­¦ç¿’ä¸­ (n_estimators=75)...")
    
    start_time = time.time()
    
    # ãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã¨åŒã˜è¨­å®šã€n_estimatorsã®ã¿å¤‰æ›´ï¼‰
    model = RandomForestRegressor(
        n_estimators=75,
        random_state=42,
        n_jobs=-1  # å…¨CPUã‚³ã‚¢ã‚’ä½¿ç”¨
    )
    
    # å­¦ç¿’å®Ÿè¡Œ
    model.fit(X_train, y_train)
    
    training_time = time.time() - start_time
    
    print(f"âœ… å­¦ç¿’å®Œäº†")
    print(f"   å­¦ç¿’æ™‚é–“: {training_time:.2f}ç§’")
    
    # äºˆæ¸¬å®Ÿè¡Œ
    print(f"\nğŸ”® äºˆæ¸¬å®Ÿè¡Œä¸­...")
    
    predict_start = time.time()
    y_pred = model.predict(X_test)
    predict_time = time.time() - predict_start
    
    # è² ã®å€¤ã‚’0ã«å¤‰æ›
    y_pred[y_pred < 0] = 0
    
    print(f"âœ… äºˆæ¸¬å®Œäº†")
    print(f"   äºˆæ¸¬æ™‚é–“: {predict_time:.3f}ç§’")
    print(f"   äºˆæ¸¬çµæœã®å½¢çŠ¶: {y_pred.shape}")
    print(f"   äºˆæ¸¬å€¤ã®ç¯„å›²: {y_pred.min():.2f} ï½ {y_pred.max():.2f}")
    print(f"   äºˆæ¸¬å€¤ã®å¹³å‡: {y_pred.mean():.2f}")
    print(f"   äºˆæ¸¬å€¤ã®æ¨™æº–åå·®: {y_pred.std():.2f}")
    
    # ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤º
    print(f"\nğŸ“Š ç‰¹å¾´é‡é‡è¦åº¦:")
    feature_importance = model.feature_importances_
    for feature, importance in zip(feature_columns, feature_importance):
        print(f"   {feature}: {importance:.4f}")
    
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    print(f"\nğŸ“„ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
    
    # ç¾åœ¨ã®æ—¥æ™‚ã§ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç”Ÿæˆ
    now = datetime.datetime.now()
    timestamp = now.strftime("%Y%m%d_%H%M%S")
    
    # æå‡ºç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    submission_copy = submission_df.copy()
    submission_copy[1] = y_pred
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
    submission_filename = f'../submissions/{timestamp}_Exercises3_Challenge_rf75_optimal.csv'
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    os.makedirs('../submissions', exist_ok=True)
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    submission_copy.to_csv(submission_filename, index=False, header=False)
    
    print(f"âœ… æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå®Œäº†")
    print(f"   ãƒ•ã‚¡ã‚¤ãƒ«å: {submission_filename}")
    
    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n" + "=" * 70)
    print(f"ğŸ“‹ å®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼")
    print(f"=" * 70)
    print(f"ãƒ¢ãƒ‡ãƒ«è¨­å®š:")
    print(f"  - ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ : RandomForestRegressor")
    print(f"  - n_estimators: 75")
    print(f"  - random_state: 42")
    print(f"  - ä½¿ç”¨ç‰¹å¾´é‡: {len(feature_columns)}å€‹")
    print(f"")
    print(f"ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
    print(f"  - å­¦ç¿’æ™‚é–“: {training_time:.2f}ç§’")
    print(f"  - äºˆæ¸¬æ™‚é–“: {predict_time:.3f}ç§’")
    print(f"  - äºˆæ¸¬å€¤ç¯„å›²: {y_pred.min():.2f} ï½ {y_pred.max():.2f}")
    print(f"  - äºˆæ¸¬å€¤å¹³å‡: {y_pred.mean():.2f}")
    print(f"")
    print(f"æœŸå¾…ã•ã‚Œã‚‹çµæœ:")
    print(f"  - ç¾åœ¨ã®ãƒ™ã‚¹ãƒˆã‚¹ã‚³ã‚¢: 3.07256739424164 (n_estimators=100)")
    print(f"  - æœŸå¾…ã‚¹ã‚³ã‚¢ç¯„å›²: 3.065 ï½ 3.075")
    print(f"  - æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„: è¨ˆç®—æ™‚é–“25%çŸ­ç¸® + åŒç­‰ä»¥ä¸Šã®æ€§èƒ½")
    print(f"")
    print(f"æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"  1. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã‚µã‚¤ãƒˆã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    print(f"  2. ã‚¹ã‚³ã‚¢çµæœã‚’è¨˜éŒ²ãƒ»åˆ†æ")
    print(f"  3. çµæœã«åŸºã¥ã„ã¦æ›´ãªã‚‹æœ€é©åŒ–ã‚’æ¤œè¨")
    print(f"=" * 70)
    
    # ã‚¹ã‚³ã‚¢è¨˜éŒ²ç”¨ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
    print(f"\nğŸ“ ã‚¹ã‚³ã‚¢è¨˜éŒ²ç”¨ã‚³ãƒ¼ãƒ‰ï¼ˆæå‡ºå¾Œã«å®Ÿè¡Œï¼‰:")
    print(f"=" * 50)
    print(f"from score_analysis import record_score")
    print(f"")
    print(f"# æå‡ºå¾Œã«ã‚¹ã‚³ã‚¢ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    print(f"score_rf75 = None  # ä¾‹: 3.070000")
    print(f"")
    print(f"if score_rf75 is not None:")
    print(f"    result = record_score(")
    print(f"        current_score=score_rf75,")
    print(f"        model_name='RandomForestRegressor (n_estimators=75)',")
    print(f"        features_used='åº—èˆ—ID, å•†å“ID, å¹´, æœˆ, å•†å“ã‚«ãƒ†ã‚´ãƒªID',")
    print(f"        notes='æœ€é©åŒ–å®Ÿé¨“: n_estimators=75'")
    print(f"    )")
    print(f"    print('ã‚¹ã‚³ã‚¢è¨˜éŒ²å®Œäº†!')")
    print(f"else:")
    print(f"    print('ã‚¹ã‚³ã‚¢ã‚’å…¥åŠ›ã—ã¦ã‹ã‚‰ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„')")
    print(f"=" * 50)

if __name__ == "__main__":
    main()