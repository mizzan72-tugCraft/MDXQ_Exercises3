# スコア記録テンプレート
from score_analysis import record_score

print("\n" + "=" * 70)
print("📝 スコア記録テンプレート（提出後に実行）")
print("=" * 70)
print("提出後、以下のコードを実行してスコアを記録してください:\n")

for n_est in n_estimators_fine:
    print(f"# n_estimators={n_est}のスコア記録")
    print(f"score_{n_est} = None  # 提出後にスコアを入力")
    print(f"if score_{n_est} is not None:")
    print(f"    record_score(")
    print(f"        current_score=score_{n_est},")
    print(f"        model_name='RandomForestRegressor (n_estimators={n_est})',")
    print(f"        features_used='店舗ID, 商品ID, 年, 月, 商品カテゴリID',")
    print(f"        notes='細密最適化実験'")
    print(f"    )")
    print()

print("=" * 70)
print("🎯 最適値発見後の次のステップ:")
print("1. 最良のn_estimators値を特定")
print("2. その設定で特徴量エンジニアリングを実施")
print("3. ハイパーパラメータの更なる調整")
print("4. 他のアルゴリズム（XGBoost, LightGBM）との比較")
print("=" * 70)## 🎯 100以下での最適値予測と理論的考察

### 予測される結果パターン

| n_estimators | 予測される性能 | 根拠 |
|-------------|-------------|------|
| **10** | 大幅に悪化 | アンサンブル効果不足、高バイアス |
| **25** | やや悪化 | 不安定性あり、まだ木が少ない |
| **50** | **良好な候補** | バランス良好、効率的 |
| **75** | **最優秀候補** | 100に近い性能、より効率的 |
| **100** | 既知のベスト | 現在の最良スコア |

### 最適値の理論的推定

**仮説**: **n_estimators=75が最適値**の可能性が高い

**理由**:
1. **アンサンブル効果の飽和点**: 一般的に50-100で性能が飽和
2. **過学習回避**: 200で悪化したため、100以下に最適値
3. **計算効率**: 75なら25%の計算時間短縮
4. **安定性**: 75本あれば十分な予測安定性

### 期待される実験結果

```
予測スコアランキング:
1. n_estimators=75  ← 最優秀候補
2. n_estimators=100 ← 既知のベスト
3. n_estimators=50  ← 効率重視候補
4. n_estimators=25  ← やや劣る
5. n_estimators=10  ← 大幅に劣る
```

### ビジネス的価値

- **75が最適なら**: 25%の計算時間短縮 + 同等性能
- **50が十分なら**: 50%の計算時間短縮 + 許容可能な性能低下
- **実用性**: より高速な推論、リソース効率化# 提出ファイル生成
now = datetime.datetime.now()
timestamp = now.strftime("%Y%m%d_%H%M%S")

print("\n" + "=" * 60)
print("📁 提出ファイル生成")
print("=" * 60)

submission_files_fine = {}
for n_est in n_estimators_fine:
    submission_copy = submission_df.copy()
    submission_copy[1] = results_fine[n_est]['predictions']
    
    filename = f'../submissions/{timestamp}_Exercises3_Challenge_rf{n_est}_fine.csv'
    submission_copy.to_csv(filename, index=False, header=False)
    
    submission_files_fine[n_est] = filename
    print(f"✅ n_estimators={n_est:2d}: {filename}")

print(f"\n🎯 {len(submission_files_fine)}個の提出ファイルが生成されました")
print("各ファイルをコンペティションサイトに提出してスコアを確認してください。")# パフォーマンス分析と可視化
plt.figure(figsize=(15, 10))

# 学習時間の可視化
plt.subplot(2, 3, 1)
times = [results_fine[n]['training_time'] for n in n_estimators_fine]
plt.plot(n_estimators_fine, times, 'bo-', linewidth=2, markersize=8)
plt.xlabel('n_estimators')
plt.ylabel('学習時間 (秒)')
plt.title('学習時間 vs n_estimators')
plt.grid(True, alpha=0.3)

# 予測値の平均
plt.subplot(2, 3, 2)
means = [results_fine[n]['pred_mean'] for n in n_estimators_fine]
plt.plot(n_estimators_fine, means, 'go-', linewidth=2, markersize=8)
plt.xlabel('n_estimators')
plt.ylabel('予測値の平均')
plt.title('予測値の平均 vs n_estimators')
plt.grid(True, alpha=0.3)

# 予測値の標準偏差
plt.subplot(2, 3, 3)
stds = [results_fine[n]['pred_std'] for n in n_estimators_fine]
plt.plot(n_estimators_fine, stds, 'ro-', linewidth=2, markersize=8)
plt.xlabel('n_estimators')
plt.ylabel('予測値の標準偏差')
plt.title('予測値のバラツキ vs n_estimators')
plt.grid(True, alpha=0.3)

# 予測値の分布比較（箱ひげ図）
plt.subplot(2, 3, 4)
pred_data = [results_fine[n]['predictions'] for n in n_estimators_fine]
plt.boxplot(pred_data, labels=n_estimators_fine)
plt.xlabel('n_estimators')
plt.ylabel('予測値')
plt.title('予測値の分布比較')
plt.yscale('log')  # 対数スケール

# 効率性指標（学習時間の逆数）
plt.subplot(2, 3, 5)
efficiency = [1/results_fine[n]['training_time'] for n in n_estimators_fine]
plt.plot(n_estimators_fine, efficiency, 'mo-', linewidth=2, markersize=8)
plt.xlabel('n_estimators')
plt.ylabel('効率性 (1/学習時間)')
plt.title('計算効率性 vs n_estimators')
plt.grid(True, alpha=0.3)

# 予測値の範囲
plt.subplot(2, 3, 6)
ranges = [results_fine[n]['pred_max'] - results_fine[n]['pred_min'] for n in n_estimators_fine]
plt.plot(n_estimators_fine, ranges, 'co-', linewidth=2, markersize=8)
plt.xlabel('n_estimators')
plt.ylabel('予測値の範囲')
plt.title('予測値の範囲 vs n_estimators')
plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# 詳細な数値比較表
print("\n" + "=" * 80)
print("📊 詳細パフォーマンス比較表")
print("=" * 80)
print(f"{'n_est':>6} {'学習時間':>8} {'予測平均':>8} {'予測std':>8} {'予測範囲':>8} {'効率性':>8}")
print("-" * 80)
for n_est in n_estimators_fine:
    r = results_fine[n_est]
    efficiency = 1/r['training_time']
    pred_range = r['pred_max'] - r['pred_min']
    print(f"{n_est:>6} {r['training_time']:>8.2f} {r['pred_mean']:>8.2f} {r['pred_std']:>8.2f} {pred_range:>8.2f} {efficiency:>8.2f}")
print("=" * 80)# 細密最適化実験（100以下）
n_estimators_fine = [10, 25, 50, 75, 100]
results_fine = {}
training_times = {}

print("=" * 70)
print("🔍 n_estimators細密最適化実験（100以下）")
print("=" * 70)
print("目標: 計算効率と予測精度の最適バランスを発見")
print("=" * 70)

for n_est in n_estimators_fine:
    print(f"\n🌳 n_estimators={n_est} で実験中...")
    
    # 学習時間の測定開始
    start_time = time.time()
    
    # モデル定義と学習
    model = RandomForestRegressor(
        n_estimators=n_est, 
        random_state=42, 
        n_jobs=-1,
        max_features='sqrt'  # デフォルト設定を明示
    )
    model.fit(X_train, y_train)
    
    # 学習時間の測定終了
    training_time = time.time() - start_time
    
    # 予測
    y_pred = model.predict(X_test)
    y_pred[y_pred < 0] = 0
    
    # 結果を保存
    results_fine[n_est] = {
        'model': model,
        'predictions': y_pred,
        'pred_min': y_pred.min(),
        'pred_max': y_pred.max(),
        'pred_mean': y_pred.mean(),
        'pred_std': y_pred.std(),
        'training_time': training_time
    }
    
    print(f"   ⏱️  学習時間: {training_time:.2f}秒")
    print(f"   📊 予測値の範囲: {y_pred.min():.2f} ～ {y_pred.max():.2f}")
    print(f"   📈 予測値の平均: {y_pred.mean():.2f}")
    print(f"   📏 予測値の標準偏差: {y_pred.std():.2f}")

print("\n✅ 全ての細密実験が完了しました")# データ読み込み・前処理（ベストモデルと同一）
base_dir = '../data/'
sales_df = pd.read_csv(base_dir + 'sales_history.csv')
item_categories_df = pd.read_csv(base_dir + 'item_categories.csv')
category_names_df = pd.read_csv(base_dir + 'category_names.csv')
test_df = pd.read_csv(base_dir + 'test.csv')
submission_df = pd.read_csv(base_dir + 'sample_submission.csv', header=None)

# データ前処理
sales_df['年'] = sales_df['日付'].apply(lambda x: x.split('-')[0])
sales_df['月'] = sales_df['日付'].apply(lambda x: x.split('-')[1])
sales_month_df = sales_df.groupby(['商品ID', '店舗ID', '年', '月'])['売上個数'].sum().reset_index()
train_df = pd.merge(sales_month_df, item_categories_df, on='商品ID', how='left')
train_df['年'] = train_df['年'].astype(int)
train_df['月'] = train_df['月'].astype(int)

test_df['年'] = 2022
test_df['月'] = 12
test_df = pd.merge(test_df, item_categories_df, on='商品ID', how='left')

feature_columns = ['店舗ID', '商品ID', '年', '月', '商品カテゴリID']
target_column = '売上個数'
X_train = train_df[feature_columns]
y_train = train_df[target_column]
X_test = test_df[feature_columns]

print("✅ データ前処理完了")
print(f"訓練データ形状: {X_train.shape}")
print(f"テストデータ形状: {X_test.shape}")# =============================================================================
# n_estimators細密最適化実験（100以下）
# =============================================================================
# 
# 【実験目的】
# - n_estimators=100がベスト（3.07256739424164）
# - n_estimators=200で悪化（3.078811806610283）
# - 100以下での最適値を細かく探索
# 
# 【実験範囲】
# [10, 25, 50, 75, 100] - より細かい刻みで最適値を特定
# 
# 【期待される結果】
# - 10: アンダーフィッティング（高バイアス）
# - 25-75: 最適値候補範囲
# - 100: 既知のベスト値
# 
# =============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import datetime
import os
import time